{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "6a352b52891f4efe95d87a5c37caef33",
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-danger\">\n\n# 3C: Traits of Fictional Characters (COMPLETE)\n\n*This notebook is intended for students who have completed up to:*\n \n**Page 3.13**\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b085cef6a05f4362976417ecaee30a58",
        "deepnote_cell_height": 459.84375,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n#### Summary of Notebook:\n\nIn this lesson, students will explore a dataset on hundreds of fictional characters (from books, movies, TV shows, video games, etc.) that have been rated on various personality traits (e.g., how loveable, tall, or moody they are perceived to be). Students will first explore models that try to explain variation in how loveable a character is, then they will get to develop their own theories and explore those models as well to see which variables do the best job explaining variation in their outcome variable. \n\n\n#### Includes:\n\n- Fitting and interpreting a model with a quantitative explanatory variable.\n- Connecting parameter estimates to visualizations.\n- Making predictions with models, and evaluating error off of the models.\n\n#### Resources:\n\n- Optional [Printable Graph Handout](https://docs.google.com/document/d/1L1ur9c3z7ctpfKEVLcAwTZb0O88pneJYjTBB1h-EHEc/edit?usp=sharing).This handout contains images of the relevant visualizations that are made throughout the lesson. They can be used for students to manually draw on, mark up, and make notes. This can give students the chance to process the graphs more deeply, and connect them to the models they are fitting.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a0e46b8f653a435c910ffb3024244a19",
        "deepnote_cell_height": 123.9375,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-success\">\n\n## Approximate time to complete Notebook: 55-75 Mins\n\n</div>"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "6e412a593abb49bc9e2d407775c54f48",
        "deepnote_cell_height": 260.953125,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 3192,
        "execution_start": 1662165673706,
        "output_cleared": true,
        "source_hash": "f00f6f4c",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# This code will load the R packages we will use\nsuppressPackageStartupMessages({\n    library(coursekata)\n})\n\n# This code will make sure the middle rows/columns don't get cut out (ellipsized) when you \n# print out a really large data frame (note: you can adjust the values for max rows/cols)\noptions(repr.matrix.max.rows=900, repr.matrix.max.cols=100)\n\n# Load the data frame\ncharacters <- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQk_n4m-VBCD7CtcpB1kOsiNDLrPmEOEtlOoaKwDhogE_YeGEW5PYTaOtZaqypEgHRFGWsZ0pdYvt_A/pub?gid=0&single=true&output=csv\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "df659cbb0e394ca9aa1cb01ad31ac4bb",
        "deepnote_cell_height": 682.21875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "## Favorite Fictional Characters\n\n<img src=\"https://i.postimg.cc/s34kFsZr/xcd-03-B-fictional-chars.png\" alt=\"A collage of the faces of various fictional characters\" width = 30%>\n\nThere are many popular fictional universes out there with their own unique set of fictional characters with a wide range of personality types. Some characters are known for being quite likeable, and some characters are known for being unlikeable, or even despised. \n\nWho are some of your favorite fictional characters (i.e., from any of your favorite books, movies, TV shows, or games)? What is it about those characters that you like?\n\nWho are some unlikeable characters? What makes them unlikeable?\n\nToday we'll explore and explain the variation in character likeability."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f3474a975bfa49b2b61d1a89eb9230e3",
        "deepnote_cell_height": 61.953125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "### Motivating Question: What traits make a character more likeable?"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "cd874b437a254d09a770a6f42a00dac9",
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "### The Dataset\n\n**Description:** The `characters` data frame contains characters from various fictional universes. More than [3 million volunteers from the internet](https://openpsychometrics.org/tests/characters/) rated these characters on various traits by using a sliding scale. For example, the character Mushu (from Disney's Mulan), is depicted below being rated on a scale from zero, rude, to 100, respectful.\n\n<img src=\"https://i.postimg.cc/tXVg4SjZ/rating-characters.png\" alt=\"example of how people rated a character with a slider\" width = 40%>\n\n##### Variable Descriptions\n\n- `char_id` The character ID.\n- `char_name` The character's name.\t\n- `uni_id` The universe ID for the book, game, movie, or TV show.\n- `uni_name` The universe name of the book, game, movie, or TV show.\n- `gender` The gender of the character (M=Male, F=Female, NB=NonBinary).\n- `abstract` The average rating of how abstract (vs concrete) the character is on a scale of 0-100 (0-concrete, 100-abstract).\n- `agreeable` The average rating of how agreeable (vs stubborn) the character is on a scale of 0-100 (0-stubborn, 100-agreeable).\t\n- `anxious` The average rating of how anxious (vs calm) the character is on a scale of 0-100 (0-calm, 100-anxious).\n- `attractive` The average rating of how attractive (vs repulsive) the character is on a scale of 0-100 (0-repulsive, 100-attractive).\t\n- `beautiful` The average rating of how beautiful (vs ugly) the character is on a scale of 0-100 (0-ugly, 100-beautiful).\t\n- `chaotic` The average rating of how chaotic (vs orderly) the character is on a scale of 0-100 (0-orderly, 100-chaotic).\n- `chill` The average rating of how chill (vs offended) the character is on a scale of 0-100 (0-offended, 100-chill).\t\n- `cool` The average rating of how cool (vs dorky) the character is on a scale of 0-100 (0-dorky, 100-cool).\t\n- `decisive` The average rating of how decisive (vs hesitant) the character is on a scale of 0-100 (0-hesitant, 100-decisive).\t\n- `emotional` The average rating of how emotional (vs unemotional) the character is on a scale of 0-100 (0-unemotional, 100-emotional).\t\n- `extrovert` The average rating of how extroverted (vs introverted) the character is on a scale of 0-100 (0-introvert, 100-extrovert).\t\n- `feminine` The average rating of how feminine (vs masculine) the character is on a scale of 0-100 (0-masculine, 100-feminine).\t\n- `future_focused` The average rating of how future-focused (vs present-focused) the character is on a scale of 0-100 (0-present-focused, 100-future-focused).\t\n- `loveable` The average rating of how loveable (vs punchable) the character is on a scale of 0-100 (0-punchable, 100-loveable).\n- `messy` The average rating of how messy (vs neat) the character is on a scale of 0-100 (0-neat, 100-messy).\t\t\n- `moody` The average rating of how moody (vs stable) the character is on a scale of 0-100 (0-stable, 100-moody).\t\t\n- `open_minded` The average rating of how open-minded (vs close-minded) the character is on a scale of 0-100 (0-close-minded, 100-open-minded).\n- `reasoned` The average rating of how reasoned (vs instinctual) the character is on a scale of 0-100 (0-instinctual, 100-reasoned).\n- `respectful` The average rating of how respectful (vs rude) the character is on a scale of 0-100 (0-rude, 100-respectful).\n- `self_assured` The average rating of how self-assured (vs self-conscious) the character is on a scale of 0-100 (0-self-conscious, 100-self-assured).\n- `self_disciplined` The average rating of how self-disciplined (vs disorganized) the character is on a scale of 0-100 (0-disorganized, 100-self-disciplined).\t\n- `tall` The average rating of how tall (vs short) the character is on a scale of 0-100 (0-short, 100-tall).\t\n- `trusting` The average rating of how trusting (vs suspicious) the character is on a scale of 0-100 (0-suspicious, 100-trusting).\n\n\n##### Data Source: \n\nOriginally collected at [Open Psychometrics](https://openpsychometrics.org/tests/characters/) made available by Tanya Shapiro as a [Tidy Tuesday data set](https://github.com/rfordatascience/tidytuesday/tree/master/data/2022/2022-08-16)."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac5175d43bfb45669a26959e756c9836",
        "deepnote_cell_height": 115.9375,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-success\">\n\n### 1.0 - Approximate Time:  10-15 mins\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c8f0acab46f849e7bac829613718a6b1",
        "deepnote_cell_height": 61.953125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "### 1.0 - Explore the Data Frame"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "16385f8aac5f45f292547a03f2ad6050",
        "deepnote_cell_height": 163.125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n**Note to Instructor:**\n\nSections 1.0 and 2.0 provide a little bit of extra code setup and scaffolding so that students can move through them a little more quickly in order to spend more time on section 3.0, where they will make their own models.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d5cf982f045842fb8d26938c7cfbe7ca",
        "deepnote_cell_height": 133.140625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Free Play\n\n**1.1:** Let's just start by getting familiar with the data we will be working with. Run the code below to get a glimpse at the data frame. Then, take a minute to freely explore the data. Look at anything interesting to you, or that you are curious about, or anything you think we might want to know about the data frame, the cases, or the variables before we start modeling anything."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "0e36e5c9ad4542c9a8d10190d993ef51",
        "deepnote_cell_height": 93.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          275.90625
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 45,
        "execution_start": 1662165676927,
        "output_cleared": true,
        "source_hash": "741887d0",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Check out the data\nhead(characters)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "cc19a884321d411aa4c18a28c205e81b",
        "deepnote_cell_height": 52.359375,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "**1.2:** What questions do you have about this data set? "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9113d6179af1427d945344dd1494fdcf",
        "deepnote_cell_height": 323.46875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n**Sample Response:**\n\nSpend some time generating questions and have students try to answer them. Here are some questions students might generate... \n\n- How many characters are represented in the data frame?\n- Which is the most/least ___ character? \n- How many fictional universes are represented in the data frame?\n- Which universes have the most/fewest number of characters represented in the data frame?\n- Is there a roughly equal number of gender categories represented?\n\n</div> \n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "allow_embed": false,
        "cell_id": "c3b5a993051e44468052d05e03b96d0a",
        "deepnote_cell_height": 1068.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          null,
          20.1875,
          610,
          58.59375,
          391.875
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 160,
        "execution_start": 1662165676969,
        "output_cleared": true,
        "source_hash": "36acdbf3",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Complete Version\n\n## How many characters?\nstr(characters)\n\n## How many universes? \n# note this code is not taught in the book\nlength(unique(characters$uni_name))\n\n## Which universes have the most/fewest characters?\nsort(tally(~uni_name, data = characters))\n\n## How many in each gender category?\ntally(~gender, data = characters)\n\n## Which characters are most attractive?\nhead(arrange(characters, desc(attractive)), 10)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c7bdac90a143434da2bab4e8103b680e",
        "deepnote_cell_height": 110.75,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Measuring Likeability\n\n**1.3--Discussion:** We are interested in modeling what predicts how likeable a character is, but there isn't a variable called \"likeable.\" Which variables in the data frame might be a good measure for this trait?"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d226487cd79143418ed8c29c99a7d3db",
        "deepnote_cell_height": 280.6875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n**Note to Instructors:**\n\nWe want to encourage students to consider what could be a stand-in (or \"operationalization\") for likeability. \n\nStudents might suggest variables such as attractive, agreeable, loveable might be ways of measuring likeability. \n\nPick one as a class. Then discuss whether there is any difference between this variable and likeability. For example, if your class chooses `loveable`, how is that variable somewhat different from likeability? Students might bring up characters that they like but do not think of as particularly lovable. Let them know that these differences are important to keep in mind even as we try to explain variation in `loveable`.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3ed7be6504dc425990f7a9d18e4e0694",
        "deepnote_cell_height": 169.921875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "**1.4:** One variable we might consider as a measure of a character's likeability is the variable `loveable`. Let's pursue that as our outcome variable together first, then afterwards, you can pursue some models using any of the other variables you are interested in as well.\n\nSo, before we develop any complex models, let's start by getting a little bit of information about `loveable`.\n\nTake a look at the visualization and empty model for `loveable` below. Describe the distribution and interpret the empty model."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "2a6a994dd4b54bf396adf1c40ae88159",
        "deepnote_cell_height": 201.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          135.421875,
          480.984375
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 534,
        "execution_start": 1662165677165,
        "output_cleared": true,
        "source_hash": "bbf36a4d",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Run this code and interpet the output\n\nempty_model <- lm(loveable ~ NULL, data = characters)\nempty_model\n\ngf_histogram(~loveable, data = characters) %>%\ngf_model(empty_model) %>%\ngf_boxplot(width = 5)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "78de8baa93b943aaa9befe09f60d04fd",
        "deepnote_cell_height": 199.515625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Sample Response:**\n\nThe distribution has a slight skew to the left. Most characters have more positive ratings (above 50) than characters with really low ratings. \n\nThe emtpy model predicts that the average loveable rating is 55.9.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c603ba34e93e45bd9b3cebabe0a7c97e",
        "deepnote_cell_height": 97.140625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "**1.5--Discussion:** Take a look at the 50 most/least `loveable` characters. Does anything stand out about the two groups of characters? Do the characters in each group have anything in common? As you look over the data, try to come up with a few theories about what might explain variation in `loveable`."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "allow_embed": false,
        "cell_id": "e7e7c3e313264025a8f7c2c22d8b51fb",
        "deepnote_cell_height": 147.96875,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          605.453125,
          605.453125
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 437,
        "execution_start": 1662165677677,
        "output_cleared": true,
        "source_hash": "2cd22426",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# The 50 most loveable characters\nhead(arrange(characters, desc(loveable)), 50)\n\n# The 50 least loveable characters\nhead(arrange(characters, loveable), 50)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5d6317f8fd7a4e6bb77e2bb563a133ce",
        "deepnote_cell_height": 345.46875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Note to Instructors:**\n\nStudents may notice various things, or get \"hunches\" about what the high/low loveable characters have in common, but if they are having trouble coming up with things, you might ask them things like:\n\n\n- Do they notice any common universes among the low vs high loveable characters?\n- Or does there appear to be one gender more represented in one group vs the other?\n- Does one group appear to have more low/high values on a particular trait?\n\n\nWhile nothing may actually stand out by just looking at a few rows of the dataset, it can still be a helpful exercise when trying to develop theories about the DGP.\n\nOf course, they can also just use their general knowledge of the world to develop theories.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c2cf4aeee31c438fbe0cc7a7ee53ee0a",
        "deepnote_cell_height": 234.921875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-success\">\n\n### 2.0 - Approximate Time:  15-20 mins\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8dc5da958ca64498a13da3a38b29a850",
        "deepnote_cell_height": 62.421875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "### 2.0 - Explaining Variation in `loveable`"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e2f2b02adda04df2a62784c4e4c87798",
        "deepnote_cell_height": 361.265625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "**2.1:** We are going to compare a few models to see which one(s) might do a better job helping us predict (i.e., explain variation in) `loveable`. \n\nWe have developed a few theories and put them into word equations below:\n\n> 1. **loveable = tall + other stuff**\n> 2. **loveable = moody + other stuff**\n> 3. **loveable = open_minded + other stuff**\n\nFor each word equation above, indicate whether you predict there will be:\n\n- a positive relationship (as x goes up, y (loveable) goes up)\n- a negative relationship (as x goes up, y (loveable) goes down)\n- some other relationship\n- no relationship"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5ea20c30406c455fbec3aa442bc35247",
        "deepnote_cell_height": 163.125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Note to Instructors:**\n\nThese three models were selected because they demonstrate a stark contrast between: a positive relationship, a negative relationship, and no relationship.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7cfac254571e4423abd7327e4a655aef",
        "deepnote_cell_height": 110.75,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Explore the Distribution\n\n**2.2:** We've set you up with some code to look at these theories in a visualization. Describe what kind of patterns you see. Does one model appear to explain more variation than the others?"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "8f57c49cf4e94cc9b561f7588786968d",
        "deepnote_cell_height": 1722.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          480.984375,
          481,
          481
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 1218,
        "execution_start": 1662167426649,
        "output_cleared": true,
        "source_hash": "765e3364",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# loveable = tall + other stuff\ngf_point(loveable ~ tall, data = characters)\n\n# loveable = moody + other stuff\ngf_point(loveable ~ moody, data = characters)\n\n# loveable = open_minded + other stuff\ngf_point(loveable ~ open_minded, data = characters)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c498791228c34e44ae78d69fbbc3c944",
        "deepnote_cell_height": 426.25,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Sample Response:**\n\n***loveable = tall + other stuff***\n\n- There does not appear to be a clear pattern. The data are very scattered and cloudy. It does not look like `tall` can help us explain much variation in `loveable`.\n\n\n***loveable = moody + other stuff***\n\n- There appears to be a negative relationship, where those who are higher on `moody` are rated lower on `loveable`. Although there is still a lot of unexplained variation, and possibly a slight curve to the data.\n\n***loveable = open_minded + other stuff***\n\n- There appears to be a positive relationship, where those who are rated more highly on `open_minded` are also rated more highly on `loveable`.\n\nThis model appears to have the strongest relationship (i.e., to explain the most variation).\n\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7cdebc2dcc044f9a8db568f193b32a5c",
        "deepnote_cell_height": 366.90625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Fit and Interpret the Models\n\n**2.3:** We've also set you up with some code to fit these models. Put them into the GLM notation we have started below, and interpret the parameter estimates. Then, engage in the discussion questions below.\n\n**GLM Notation:**\n\n> - $loveable_i = b_0 + b_1(tall_i) + e_i$\n> - $loveable_i = b_0 + b_1(moody_i) + e_i$\n> - $loveable_i = b_0 + b_1(open\\_minded_i) + e_i$\n\n***Discussion Questions:***\n\nCompare the $b_1$ estimates of the three models. Why are some negative? Which model has the smallest (or largest) $b_1$ (in absolute value)? What does this suggest?\n\nAlso, compare the $b_0$ estimates of the three models. Are they similar? Different? Why is that?"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ba90a7bda79f4603bdb7a2f64843e546",
        "deepnote_cell_height": 255.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          135.421875,
          135.421875,
          135.421875
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 269,
        "execution_start": 1662165678559,
        "output_cleared": true,
        "source_hash": "9627cd59",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# loveable = tall + other stuff\ntall_model <- lm(loveable ~ tall, data = characters)\ntall_model\n\n# loveable = moody + other stuff\nmoody_model <- lm(loveable ~ moody, data = characters)\nmoody_model\n\n# loveable = open_minded + other stuff\nopen_minded_model <- lm(loveable ~ open_minded, data = characters)\nopen_minded_model"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a13526cab1e649b8a349ab5de5ba4d95",
        "deepnote_cell_height": 813.046875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Sample Response:**\n\n- $loveable_i = 56.79 + (-0.02)(tall_i) + e_i$\n\n> The $b_0$ estimate is 56.79; this is the y-intercept, and the prediction for `loveable` when `tall` is zero. The $b_1$ estimate is -0.02; this is the slope, and is how much we subtract from $b_0$ for every 1 unit increase in `tall`.\n\n- $loveable_i = 91.17 + (-0.58)(moody_i) + e_i$\n\n> The $b_0$ estimate is 91.17; this is the y-intercept, and the prediction for `loveable` when `moody` is zero. The $b_1$ estimate is -0.58; this is the slope, and is how much we subtract from $b_0$ for every 1 unit increase in `moody`.\n\n- $loveable_i = 11.40 + 0.81(open\\_minded_i) + e_i$\n \n > The $b_0$ estimate is 11.40; this is the y-intercept, and the prediction for `loveable` when `tall` is zero. The $b_1$ estimate is 0.81; this is the slope, and is how much we add to $b_0$ for every 1 unit increase in `open_minded`.\n\n ***$b_0$ comparisons:***\n\n One way the $b_0$ estimates are similar is that they are all positive values. Other than that they are not very similar. This is because each model has a very different pattern, so the starting off point for the y-axis (for `loveable`) will be different. For the `tall` model, the predictions don't change much, so they start off near the mean (and pretty much stay there, since $b_1$ for the tall model is so small). For the `moody` model, there is a downward slope, so the predictions start off high on the y-axis (`loveable`), and the `open_minded` model has an upward trend, so the predictions start off low on the y-axis.\n\n ***$b_1$ comparisons:*** \n\nSome of the $b_1$ estimates are negative because their regression line has a downward slope, so as the explanatory variable goes up, the prediction for the outcome variable goes down. The `open_minded` model has the largest $b_1$ (in absolute value); this suggests that it might explain the most variation because it predicts the biggest change in $Y$ from the effect of $X$. This also suggests that the `tall` model will explain the least variation, because it is closest to zero.\n\n**Note to Instructors:**\n\nPart of the goal in this discussion exercise is to make sure students are also connecting the parameter estimates to the units of the outcome variable. So, even though it does not explicitly ask them to clarify what the units are, you may want to further emphasize that, if they are having trouble making that connection.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5a39313b1fb84832a1a9cabfda009f65",
        "deepnote_cell_height": 147.125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-info\">\n\n<b> <font size=\"+1\">Key Question</font></b>\n\n**2.4:**  Add the models to the visualizations and connect the parameter estimates to the model in the graph.\n\n</div>"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "allow_embed": false,
        "cell_id": "e264af679f46457b95e416e789771f52",
        "deepnote_cell_height": 309.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          480.984375,
          480.984375,
          480.984375
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 734,
        "execution_start": 1662167443806,
        "output_cleared": true,
        "source_hash": "abf13854",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Sample Responses\n\n# loveable = tall + other stuff\ngf_point(loveable ~ tall, data = characters) %>%\n    gf_model(loveable ~ tall, data = characters, color = \"red\")\n\n# loveable = moody + other stuff\ngf_point(loveable ~ moody, data = characters) %>%\n    gf_model(moody_model, color = \"red\")\n\n# loveable = open_minded + other stuff\ngf_point(loveable ~ open_minded, data = characters) %>%\n    gf_lm(color = \"red\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "696b5def0a4e44f0aefbbce3c4851a9f",
        "deepnote_cell_height": 258.5,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Sample Response:**\n\nThe $b_0$ is where the regression line runs through the y-axis, and the $b_1$ is the vertical increase or decrease (the slope of the line) from one unit of X to the next.\n\n**Note to Instructors:**\n\nYou may want to use the printable graph handout in this section so students can manually draw out these ideas and make notes.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0290499eb12f4cbc878efb5f342c82c8",
        "deepnote_cell_height": 110.75,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Make Predictions with the Models\n\n**2.5:** Make some predictions with the models. For example, what does the model predict for a character who is rated as very tall (e.g., a rating of 75)? How about a character who is rated not very tall (e.g., a rating of 25)?"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9ab7d9e02695438390136049075f477b",
        "deepnote_cell_height": 720.78125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Sample Response:**\n\n***Using the visualization to make rough predictions:***\n\nThe `tall` model predicts roughly the same value for tall characters and short characters (close to the mean of `loveable`). \n\nThe `moody` model predicts that those with a 75 moody rating will be rated just under 50 on loveable, and a moody rating of 25 will have a loveable rating of about 75.\n\nThe `open_minded` model predicts that those with a 75 open-minded rating will be rated just under 75 on loveable, and an open-minded rating of 25 will have a loveable rating of a little over 25.\n\n***Using the parameter estimates to make more precise predictions:***\n\nTall:\n\n- loveable_i = 56.79 + (-0.02)(75) = 55.29\n- loveable_i = 56.79 + (-0.02)(25) = 56.29\n\nMoody:\n\n- loveable_i = 91.17 + (-0.58)(75) = 47.67\n- loveable_i = 91.17 + (-0.58)(25) = 76.67\n\nOpen Minded:\n\n- loveable_i = 11.40 + 0.81(75) = 72.15\n- loveable_i = 11.40 + 0.81(25) = 31.65\n\n**Note to Instructors:**\n\nTry to get students to make predictions both ways (rough estimations by looking at the model in the visualization, and precise estimates with the GLM). Of course, they can also use R code (such as the predict() function) as well.\n\n</div>"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "96ea3c1835d64b6eb21d859ea5cb43fa",
        "deepnote_cell_height": 336.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          20.1875,
          20.1875,
          20.1875,
          20.1875,
          20.1875,
          20.1875
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 60,
        "execution_start": 1662165679374,
        "output_cleared": true,
        "source_hash": "831fbef0",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "56.79 + (-0.02*75) \n56.79 + (-0.02*25) \n91.17 + (-0.58*75) \n91.17 + (-0.58*25) \n11.40 + (0.81*75)\n11.40 + (0.81*25) "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "allow_embed": false,
        "cell_id": "294ecb3fca4843a28d9febb5ac32203d",
        "deepnote_cell_height": 165.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          20.1875,
          20.1875,
          20.1875
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 34,
        "execution_start": 1662165679457,
        "output_cleared": true,
        "source_hash": "5cd92b5e",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "56.79 + (-0.02*42.4) \n\n91.17 + (-0.58*66.1) \n\n11.40 + (0.81*71.4)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a695a26727954787b8f02c7531921efa",
        "deepnote_cell_height": 74.75,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "**2.6:** Take a look at the character selected below (or filter for another character). How far off is the model prediction for that character?"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "faeeafa3b8b7465faca129b3cb92aa63",
        "deepnote_cell_height": 93.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          130.9375
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 4,
        "execution_start": 1662165679490,
        "output_cleared": true,
        "source_hash": "25d7268",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Select the row for a particular character (e.g., Harry Potter)\ncharacters[characters$char_name == \"Harry Potter\", ]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "bd1ca4aa92c749b0b35508240c01a426",
        "deepnote_cell_height": 111.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          20.1875,
          20.1875,
          20.1875
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 2,
        "execution_start": 1662165679538,
        "output_cleared": true,
        "source_hash": "4725759e",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "59.4 - 55.94\n59.4 - 52.83 \n59.4 - 69.23"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "30efc304d24842b7b5cefcff453ee8f2",
        "deepnote_cell_height": 395.46875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n**Sample Response:**\n\n***The actual `loveable` rating for Harry Potter = 59.4***\n\n\nHarry Potter's `tall` rating = 42.4:\n\n--> loveable_i = 56.79 + (-0.02)(42.4) = 55.94 *(Residual: 59.4 - 55.94 = 3.46)*\n\nHarry Potter's `moody` rating = 66.1:\n\n--> loveable_i = 91.17 + (-0.58)(66.1) = 52.83 *(Residual: 59.4 - 52.83 = 6.57)*\n\nHarry Potter's `open_minded` rating = 71.4:\n\n--> loveable_i = 11.40 + 0.81(71.4) = 69.23 *(Residual: 59.4 - 69.23 = -9.83)*\n\nIn this case, the tall model has the smallest residual when predicting Harry Potter's `loveable` rating.\n\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c7e62a298031467dbbfa29cd80efcdae",
        "deepnote_cell_height": 205.515625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Evaluate the Models\n\n<div class=\"alert alert-block alert-info\">\n\n<b> <font size=\"+1\">Key Question</font></b>\n\n**2.7:** How much variation in `loveable` does each model explain? Are any of the models much better than the empty model? And, if so, which model explains the most variation in `loveable`. Use statistics to support your answer.\n\n</div>"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "2f9ef08dc2964fdda0aefbf09920721e",
        "deepnote_cell_height": 237.96875,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 1,
        "execution_start": 1662165679550,
        "output_cleared": true,
        "source_hash": "f17ecc1f",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Here are the saved model names to get you started\n\n# loveable = tall + other stuff\n# tall_model\n\n# loveable = moody + other stuff\n# moody_model\n\n# loveable = open_minded + other stuff\n# open_minded_model"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "allow_embed": false,
        "cell_id": "87b6d39d3b394c4486f943c63a88205f",
        "deepnote_cell_height": 237.96875,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          173.828125,
          173.828125,
          173.828125
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 31,
        "execution_start": 1662165679597,
        "output_cleared": true,
        "source_hash": "cadffdc2",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Complete Version\n\n# loveable = tall + other stuff\nsupernova(tall_model)\n\n# loveable = moody + other stuff\nsupernova(moody_model)\n\n# loveable = open_minded + other stuff\nsupernova(open_minded_model)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d021712ab42e40cbbef9f45dd75c1412",
        "deepnote_cell_height": 403.859375,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n**Sample Response:**\n\nTall:\n\nThe `tall` model explains about zero percent (0.0004) of the variation in `loveable` according the PRE.\n\nMoody:\n\nThe `moody` model explains about 28% of the variation in `loveable` according the PRE.\n\nOpen-Minded:\n\nThe `open_minded` model explains about 55% of the variation in `loveable` according the PRE.\n\nThe `tall` model is not any better than the empty model. The `open_minded` model explains the most variation when comparing the PREs. It also has the largest F value, and the highest SS Model. Or, it also has the lowest SS Error, which means it has the least amount of leftover (or unexplained) variation.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "594a9f18743b4cdfbf0eeaadfffefb2f",
        "deepnote_cell_height": 115.9375,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-success\">\n\n### 3.0 - Approximate Time:  20-25 mins\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9025a89ba2a044759b30049cda198fb9",
        "deepnote_cell_height": 61.953125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "### 3.0 - Make Your Own Models"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b3cb1ded52934b0eb13d9eb6dec830f1",
        "deepnote_cell_height": 124.75,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Explore the Distribution\n\n**3.1:** Take a look through the data and select a character trait that you are interested in as an outcome variable. \n\nCreate a visualization to explore the distribution, and fit the empty model.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ea814a25dff44b8b9e548e68563649f5",
        "deepnote_cell_height": 273.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          480.984375,
          135.421875,
          480.984375
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 355,
        "execution_start": 1662165679693,
        "output_cleared": true,
        "source_hash": "103588e7",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Example Outcome Variable: chill\n\n# Sample Visualization\ngf_histogram(~chill, data = characters) %>%\n    gf_boxplot(fill = \"white\", width = 9)\n\n# Sample Visualization\ngf_boxplot(chill~1, data = characters)\n\n# Sample Empty Model\nempty_chill_model <- lm(chill ~ NULL, data = characters)\nempty_chill_model"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7f42b35967a741348522c0dd6403a15c",
        "deepnote_cell_height": 133.53125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "**3.2:** Come up with two different theories about the DGP for that variable, and write them as word equations (i.e., pick two explanatory variables).\n\n\nMake some predictions about what you might expect to find, then create visualizations to explore your hypotheses. Describe what you see. Does one model appear to explain more variation than the others?"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "f4715566ef9a4a1aa37cc51567ef53c9",
        "deepnote_cell_height": 183.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          480.984375,
          480.984375
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 399,
        "execution_start": 1662165680053,
        "output_cleared": true,
        "source_hash": "8e5eea3d",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Sample Response\n\n# chill = chaotic + other stuff\ngf_point(chill ~ chaotic, data = characters)\n\n# chill = extrovert + other stuff\ngf_point(chill ~ extrovert, data = characters)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bee9e6cd65a34347becba3684f9855f5",
        "deepnote_cell_height": 359.078125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n**Sample Response:**\n\n***Example Student Theories:***\n\n- chill = chaotic + other stuff\n\n\"I predict that the more chaotic a character is rated, the less chill they will be rated.\"\n\n- chill = extrovert + other stuff\n\n\"I predict that the more introverted a character is rated, the more chill they will be rated.\"\n\n***Visualizations:***\n\nIt does not look like `chaotic` nor `extrovert` explain much variation in `chill`. They both have very cloudy, scattered data. \n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4532cb2cdff64052b01b9ca02d94e5f4",
        "deepnote_cell_height": 88.5625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Fit and Interpret the Models\n\n**3.3:** Fit your models, put them into GLM notation ($Y_i = b_0 + b_1(X_i) + e_i$), and interpret the parameter estimates."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "3dfc1baaa5d64af18868b33c3cf2e50d",
        "deepnote_cell_height": 219.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          135.421875,
          135.421875
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 29,
        "execution_start": 1662165680442,
        "output_cleared": true,
        "source_hash": "ddfe249d",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Sample Response\n\n# chill = chaotic + other stuff\nchaotic_model <- lm(chill ~ chaotic, data = characters)\nchaotic_model\n\n# chill = extrovert + other stuff\nextrovert_model <- lm(chill ~ extrovert, data = characters)\nextrovert_model"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b7075b57010a4c5a96423dc6b3d9aeb5",
        "deepnote_cell_height": 413.90625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Sample Response:**\n\n- $chill_i = 43.29 + 0.02(chaotic_i) + e_i$\n \n > The $b_0$ estimate is 43.29; this is the y-intercept, and the prediction for `chill` when `chaotic` is zero. The $b_1$ estimate is 0.02; this is the slope, and is how much we add to $b_0$ for every 1 unit increase in `chaotic`.\n\n- $chill_i = 44.06 + 0.00(extrovert) + e_i$\n \n > The $b_0$ estimate is 44.06; this is the y-intercept, and the prediction for `chill` when `extrovert` is zero. The $b_1$ estimate is 0.00; this is the slope, and is how much we add to $b_0$ for every 1 unit increase in `extrovert`.\n\n\n**Note to Instructors:**\n\nYou may also want to get them to discuss and compare the parameter estimates for the two models, as they did in section 2.0. For instance, in the example models (chill = chaotic/extrovert), the $b_0$s are pretty close and hover near the mean of chill, and the $b_1$s are near zero. This suggests, as with the loveable = tall model, that they probably do not explain much variation in `chill`.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "149eb97251ee4e16943585ac8f3c3fcb",
        "deepnote_cell_height": 147.125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-info\">\n\n<b> <font size=\"+1\">Key Question</font></b>\n\n**3.4:** Add the models to your visualizations, and connect the parameter estimates to the models in the graphs.\n\n</div>"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "allow_embed": false,
        "cell_id": "fb7f175300964a658ba43a8a82c5c7b7",
        "deepnote_cell_height": 219.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          480.984375,
          480.984375
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 1125,
        "execution_start": 1662165680475,
        "output_cleared": true,
        "source_hash": "bd5b6e56",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Sample Responses\n\n# chill = chaotic + other stuff\ngf_point(chill ~ chaotic, data = characters) %>%\n    gf_lm(color = \"red\")\n\n# chill = extrovert + other stuff\ngf_point(chill ~ extrovert, data = characters) %>%\n    gf_model(extrovert_model, color = \"red\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "527f59dd23954a748d2895d7c78eeb65",
        "deepnote_cell_height": 110.75,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Make Predictions with the Models\n\n**3.5:** Make some predictions with the models. For example, what does the model predict for a character who is low in that trait versus a character who is high in that trait?"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5e5acf4c42ec413f9b0e3cd37ec20b39",
        "deepnote_cell_height": 140.71875,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Sample Response:**\n\nIn the example models, the predictions for `chill` do not really change for high vs low ratings on `chaotic` nor `extrovert`.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0ce82fb36c46464d8ca773f5aa90f197",
        "deepnote_cell_height": 205.515625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "#### Evaluate the Models\n\n<div class=\"alert alert-block alert-info\">\n\n<b> <font size=\"+1\">Key Question</font></b>\n\n**3.6:** How much variation in your outcome variable does each model explain? Are any of the models much better than the empty model? And, if so, which model explains the most variation in your outcome variable? Use statistics to support your answer.\n\n</div>"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "6314b3f5dc1a4849b31248cb15f9d178",
        "deepnote_cell_height": 129.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          173.828125,
          173.828125
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 10,
        "execution_start": 1662166315341,
        "output_cleared": true,
        "source_hash": "9570368",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Sample Responses\n\nsupernova(chaotic_model)\nsupernova(extrovert_model)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0e3a3d9d158f4364979d3c2e23a8a71d",
        "deepnote_cell_height": 185.515625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Sample Response:**\n\nIn the example models, neither of the explanatory variables explain any variation in the outcome variables. They both have a PRE of zero (or, less than .001), and their SS Error is very close their SS Total, meaning the model did not reduce very much error at all. Both of the models are as good as the empty model.\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "54fa298ee57e44f9aa4ea524ed5eb2a1",
        "deepnote_cell_height": 115.9375,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-success\">\n\n### 4.0 - Approximate Time:  10-15 mins\n\n</div>"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "2691396fee4740259a7b08a10790fa91",
        "deepnote_cell_height": 61.953125,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "### 4.0 - BONUS: Explore A Universe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "059e177e50304f51b302ba4682164eb1",
        "deepnote_cell_height": 52.359375,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "**4.1:** Try filtering the data for a particular fictional universe that you are interested in (probably one with at least 10+ characters). "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "d10535c8649e492faf390cdffa04a2a3",
        "deepnote_cell_height": 183.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          275.90625
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 49,
        "execution_start": 1662166478596,
        "output_cleared": true,
        "source_hash": "272ddaf",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "## Just in case: Check which universes have the most/fewest characters\n# sort(tally(~uni_name, data = characters))\n\n# Sample Response -- filtering for the Harry Potter universe\n\ncharacters_HP <- filter(characters, uni_name == \"Harry Potter\")\nhead(characters_HP)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "24cd82eab5b44041ae400900575afcef",
        "deepnote_cell_height": 74.75,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "**4.2:** How do the trends for that universe compare to the trends you found when looking at all the universes? Are the trends for those characters similar to the trends for the broader set of characters, or are they quite different? Why do you think that is?"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "df05d76e6efd4d649f12e319c1b897c9",
        "deepnote_cell_height": 471.953125,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          481,
          480.984375,
          480.984375,
          480.984375,
          173.828125,
          173.828125,
          173.828125,
          173.828125,
          173.828125,
          480.984375,
          480.984375
        ],
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 1877,
        "execution_start": 1662166934001,
        "output_cleared": true,
        "source_hash": "23fcd876",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# Sample Responses\n\ngf_point(loveable ~ tall, data = characters_HP) %>% \n    gf_lm()\ngf_point(loveable ~ moody, data = characters_HP) %>% \n    gf_lm()\ngf_point(loveable ~ open_minded, data = characters_HP) %>% \n    gf_lm()\n\n\ngf_point(chill ~ chaotic, data = characters_HP) %>% \n    gf_lm()\ngf_point(chill ~ extrovert, data = characters_HP) %>% \n    gf_lm()\n\n\nsupernova(lm(loveable ~ tall, data = characters_HP)) \nsupernova(lm(loveable ~ moody, data = characters_HP)) \nsupernova(lm(loveable ~ open_minded, data = characters_HP)) \n\nsupernova(lm(chill ~ chaotic, data = characters_HP)) \nsupernova(lm(chill ~ extrovert, data = characters_HP)) \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a56ef98b49194a89bc9efaf6889f6fad",
        "deepnote_cell_height": 221.90625,
        "deepnote_cell_type": "markdown",
        "tags": []
      },
      "source": "<div class=\"alert alert-block alert-warning\">\n\n\n**Sample Response:**\n\nSome students may notice that there are different trends for one universe compared to all the universes. Ask them why they think that is.\n\nFor instance, how might the difference in sample size affect things? What are some aspects of the universe itself that might lead to different trends in the personalities of the characters?\n\n</div>"
    }
  ],
  "metadata": {
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "b00d1b216ed94f7fbd674d422ea7488b",
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.2"
    },
    "nbsimplegrader": {
      "publish_config": {
        "classes": [],
        "options": {},
        "tools": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}